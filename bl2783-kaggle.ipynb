{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/f2019-aihw7/mnist-train-labels.npy\n",
      "/kaggle/input/f2019-aihw7/mnist-train-images.npy\n",
      "/kaggle/input/f2019-aihw7/mnist-val-images.npy\n",
      "/kaggle/input/f2019-aihw7/scan-train-labels.npy\n",
      "/kaggle/input/f2019-aihw7/scan-test-images.npy\n",
      "/kaggle/input/f2019-aihw7/mnist-val-labels.npy\n",
      "/kaggle/input/f2019-aihw7/scan-train-images.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# These paths are unique to Kaggle, obviously. Use your local path or colab path, depending on which you're using.\n",
    "mnist_train_x = np.load('/kaggle/input/f2019-aihw7/mnist-train-images.npy')\n",
    "mnist_train_y = np.load('/kaggle/input/f2019-aihw7/mnist-train-labels.npy')\n",
    "mnist_val_x = np.load('/kaggle/input/f2019-aihw7/mnist-val-images.npy')\n",
    "mnist_val_y = np.load('/kaggle/input/f2019-aihw7/mnist-val-labels.npy')\n",
    "scan_train_x = np.load('/kaggle/input/f2019-aihw7/scan-train-images.npy')\n",
    "scan_train_y = np.load('/kaggle/input/f2019-aihw7/scan-train-labels.npy')\n",
    "scan_test_x = np.load('/kaggle/input/f2019-aihw7/scan-test-images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = 2500\n",
    "train_x = np.vstack((mnist_train_x,scan_train_x[:pivot]))\n",
    "train_y = np.hstack((mnist_train_y,scan_train_y[:pivot]))\n",
    "val_x = np.vstack((mnist_val_x,scan_train_x[pivot:]))\n",
    "val_y = np.hstack((mnist_val_y,scan_train_y[pivot:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3,ax4,ax5) = plt.subplots(nrows=1, ncols=5)\n",
    "i = 1234\n",
    "ax1.imshow(scan_test_x[i+1], cmap=plt.get_cmap('gray'))\n",
    "ax2.imshow(scan_test_x[i+2], cmap=plt.get_cmap('gray'))\n",
    "ax3.imshow(scan_test_x[i+3], cmap=plt.get_cmap('gray'))\n",
    "ax4.imshow(scan_test_x[i+4], cmap=plt.get_cmap('gray'))\n",
    "ax5.imshow(scan_test_x[i+5], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "train_x = train_x[:,:,:,np.newaxis].astype(np.float)/255\n",
    "val_x = val_x[:,:,:,np.newaxis].astype(np.float)/255\n",
    "train_y = keras.utils.to_categorical(train_y, 10)\n",
    "val_y = keras.utils.to_categorical(val_y, 10)\n",
    "\n",
    "scan_test_x = scan_test_x[:,:,:,np.newaxis].astype(np.float)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten,Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (5,5), activation='relu', input_shape=(28, 28, 1),dilation_rate=(1, 1)),\n",
    "    Conv2D(64, (5,5), activation='relu',dilation_rate=(1, 1)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.SGD(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62500 samples, validate on 11280 samples\n",
      "Epoch 1/10\n",
      "62500/62500 [==============================] - 17s 278us/step - loss: 0.4385 - accuracy: 0.8598 - val_loss: 0.1039 - val_accuracy: 0.9690\n",
      "Epoch 2/10\n",
      "62500/62500 [==============================] - 16s 250us/step - loss: 0.1509 - accuracy: 0.9547 - val_loss: 0.0697 - val_accuracy: 0.9776\n",
      "Epoch 3/10\n",
      "62500/62500 [==============================] - 16s 252us/step - loss: 0.1126 - accuracy: 0.9660 - val_loss: 0.0499 - val_accuracy: 0.9850\n",
      "Epoch 4/10\n",
      "62500/62500 [==============================] - 16s 255us/step - loss: 0.0954 - accuracy: 0.9711 - val_loss: 0.0472 - val_accuracy: 0.9846\n",
      "Epoch 5/10\n",
      "62500/62500 [==============================] - 16s 250us/step - loss: 0.0816 - accuracy: 0.9753 - val_loss: 0.0398 - val_accuracy: 0.9871\n",
      "Epoch 6/10\n",
      "62500/62500 [==============================] - 16s 251us/step - loss: 0.0740 - accuracy: 0.9775 - val_loss: 0.0380 - val_accuracy: 0.9876\n",
      "Epoch 7/10\n",
      "62500/62500 [==============================] - 16s 260us/step - loss: 0.0680 - accuracy: 0.9796 - val_loss: 0.0347 - val_accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "62500/62500 [==============================] - 16s 250us/step - loss: 0.0625 - accuracy: 0.9817 - val_loss: 0.0322 - val_accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "62500/62500 [==============================] - 16s 251us/step - loss: 0.0598 - accuracy: 0.9819 - val_loss: 0.0318 - val_accuracy: 0.9896\n",
      "Epoch 10/10\n",
      "62500/62500 [==============================] - 16s 250us/step - loss: 0.0536 - accuracy: 0.9836 - val_loss: 0.0314 - val_accuracy: 0.9907\n",
      "Training took 159.56786465644836 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model.fit(train_x,        # training data\n",
    "          train_y,        # training labels\n",
    "          batch_size=16,  # how many training examples you want to give at once\n",
    "          verbose=1,      # print progress in console\n",
    "          validation_data=(val_x, val_y),  # validation data to check generalization\n",
    "          epochs=10)       # how many times to go through the entire training set\n",
    "end = time.time()\n",
    "print(\"Training took\", end-start, \"seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "pred = np.argmax(model.predict(scan_test_x),axis = 1)\n",
    "with open('res.csv','w',newline='')as f:\n",
    "            csv_write=csv.writer(f)\n",
    "            csv_write.writerow(['Id','Category'])\n",
    "            for i in range(len(pred)):\n",
    "                csv_write.writerow([i,pred[i]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
